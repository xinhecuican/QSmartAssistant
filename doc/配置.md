配置目录在`~/.config/QSmartAssistant`，插件和配置文件都在该目录下，程序目录下Data文件夹会自动复制到配置目录中

配置文件为`Data/config.json`,修改配置文件之后进入build目录运行`cmake ..`会自动复制配置文件到配置目录

第一次运行可以将`Data/default_config.json`复制为`Data/config.json`

# wakeup

模型比较：

| 模型    | 选项             | cpu占用 | 内存占用 |
| ------- | ---------------- | ------- | -------- |
| duilite | -DWAKEUP_DUILITE |         |          |

通用选项：`wakeup`

| 选项           | 默认值 | 含义                                                         |
| -------------- | ------ | ------------------------------------------------------------ |
| chunkSize      | 640    | 默认音频块的大小，默认一个音频块包含20ms的音频               |
| detectSlient   | 800    | vad检测到人声后停止检测的间隔，默认检测到人声后800ms没有人声则停止检测 |
| undetectSlient | 4000   | 没有检测到人声时最长检测时间，默认4s没有人声退出vad          |
| minChunk       | 3      | 最少检测音频数量，若检测到包含人声的chunk数量小于3则取消asr  |



## duilite

选项：`duilite`

| 选项      | 默认值             | 含义                                                         |
| --------- | ------------------ | ------------------------------------------------------------ |
| login     | duilite_login.json | duilite的登录配置文件，[详见](https://github.com/xinhecuican/lowpower-robot/wiki/%E5%AE%89%E8%A3%85#wakeup) |
| res       | wakeup_far.bin     | 资源文件，可以自行从duilite控制台中查找                      |
| wakeword  | ni hao xiao zhi    | 唤醒词，输入为中文拼音，拼音之间以逗号隔开，默认唤醒词为`你好小智` |
| thresh    | 0.15               | 唤醒阈值，阈值越高越容易唤醒，但是误唤醒率越高。该项非常敏感，建议每次修改0.01到0.02 |
| chunkSize | 640                | 输入块的大小，默认是20ms                                     |

## porcupine

选项： `porcupine`

| 选项        | 默认值                 | 含义                                                         |
| ----------- | ---------------------- | ------------------------------------------------------------ |
| keyword     | 小云_zh.ppn            | 唤醒词模型，从[控制台](https://picovoice.ai/)中训练及下载，中文最多三个词 |
| model       | porcupine_params_zh.pv | 语言模型，中文无需改变                                       |
| key         | xxx                    | 控制台中获得                                                 |
| sensitivity | 0.5                    | 越高越容易唤醒                                               |

## openwakeword

选项：`openwakeup`

| 选项  | 默认值              | 含义                                        |
| ----- | ------------------- | ------------------------------------------- |
| model | nihao_wenwen.tflite | 模型文件，默认唤醒词为`nihao_wenwen.tflite` |

## snowboy

选项：`snowboy`

| 选项      | 默认值       | 含义                                                         |
| --------- | ------------ | ------------------------------------------------------------ |
| resource  | common.res   | 通用资源文件，可以在[这里找到](https://github.com/Kitt-AI/snowboy/tree/master/resources) |
| thres     | 0.8          | 阈值越高越容易唤醒                                           |
| model     | snowboy.umdl | 唤醒词模型                                                   |
| chunkSize | 3200         | 每次接受块的大小，默认为0.1s                                 |

## sherpa wakeup

选项： `sherpa_wakeup`

模型下载

```sh
cd Data
wget -qq https://github.com/pkufool/keyword-spotting-models/releases/download/v0.1/sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01.tar.bz
tar xf sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01.tar.bz
ls -lh sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01
```



| 选项    | 默认值                                                  | 含义                                                         |
| ------- | ------------------------------------------------------- | ------------------------------------------------------------ |
| model   | sherpa-kws/%1-epoch-12-avg-2-chunk-16-left-64.int8.onnx | asr模型，目前只有这个模型支持wakeup                          |
| thres   | 0.5                                                     | 阈值                                                         |
| score   | 0.5                                                     | 和上面的thres共同调节                                        |
| tokens  | sherpa-kws/tokens.txt                                   | token文件，模型文件夹中自带                                  |
| hotword | sherpa-kws/keywords.txt                                 | 唤醒词，具体生成方式[参照](https://k2-fsa.github.io/sherpa/onnx/hotwords/index.html) |

# vad

## cobra

选项： `cobra`

| 选项      | 默认值 | 含义                         |
| --------- | ------ | ---------------------------- |
| cofidence | 0.5    | 置信度，越高越难被认为是人声 |

## duilitevad

选项：`duilite`

需要chunkSize，login选项，可以[参照wakeup](#duilite)

| 选项   | 默认值              | 含义                           |
| ------ | ------------------- | ------------------------------ |
| vadRes | vad_aicar_v0.16.bin | 资源文件，可自行在控制台中下载 |

## silerovad

选项: `silero`

| 选项   | 默认值              | 含义                           |
| ------ | ------------------- | ------------------------------ |
| model | silero_vad.onnx  | 模型路径 |
| chunkSize | 1024 | silero v5中默认为1024，v4默认为640 |
| thresh | 0.1 | 阈值，越大越难检测出声音 |
| abandonNum | 5 | 检测开始时抛弃的块数量 |

# asr

# sherpa asr

选项：`sherpa`

[模型下载](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/index.html#)：

```sh
cd Data
wget https://hub.nuaa.cf/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-paraformer-zh-2023-09-14.tar.bz2
tar xvf sherpa-onnx-paraformer-zh-2023-09-14.tar.bz2
mv sherpa-onnx-paraformer-zh-2023-09-14 sherpa_paraformer
```



| 选项   | 默认值                            | 含义                                                         |
| ------ | --------------------------------- | ------------------------------------------------------------ |
| model  | sherpa_paraformer/model.int8.onnx | 模型文件，如果包含多个文件则不同的部分使用`%1`代替，例如`%1-epoch-12-avg-2-chunk-16-left-64.int8.onnx` |
| tokens | sherpa_paraformer/tokens.txt      | token文件，模型文件夹中都有token文件                         |
| stream | false                             | 是否为流式模型                                               |

# tts

## sherpa tts

选项： `sherpa_tts`

模型下载：

```sh
cd Data
GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/csukuangfj/vits-zh-aishell3
cd vits-zh-aishell3
git lfs pull --include "*.onnx"
```



| 选项         | 默认值                                   | 含义                                 |
| ------------ | ---------------------------------------- | ------------------------------------ |
| model        | vits-zh-aishell3/vits-aishell3.int8.onnx | 模型文件                             |
| lexicon      | vits-zh-aishell3/lexicon.txt             | 词法文件，在模型文件夹下都包含       |
| tokens       | vits-zh-aishell3/tokens.txt              | 模型文件夹中包含                     |
| rules        | vits-zh-aishell3/rule.fst                | 模型文件夹中包含                     |
| data_dir     | espeak-ng-data                           | 使用piper模型时需要                  |
| length       | 1                                        | 越大语速越慢                         |
| noise        | 0.3                                      | 控制样本随机性                       |
| noise-w      | 0.2                                      | 控制音素发音长度                     |
| speakerid    | 66                                       | 说话人id，当模型中有多个说话人时有效 |
| extra_volume | 0                                        | 额外增加的音量，以分贝为单位         |

# nlu

## baidu nlu

选项： `unit`

| 选项       | 默认值 | 含义                                                         |
| ---------- | ------ | ------------------------------------------------------------ |
| apiKey     | xxx    | 从[控制台](https://ai.baidu.com/unit/v2#/presetskill/1304181/%E9%9F%B3%E4%B9%90/detail)中获得 |
| secret     | xxx    | 从控制台中获得                                               |
| unitId     | xxx    | 从控制台中获得                                               |
| confThresh | 50     | 置信度，如果一个意图置信度低于该值则排除                     |

## rasa

选项： `rasa`

| 选项           | 默认值                          | 含义                                                         |
| -------------- | ------------------------------- | ------------------------------------------------------------ |
| model          | Data/rasa/models/default.tar.gz | 模型文件                                                     |
| record_samples | true                            | 自动记录对话并生成训练语料，结果保存在`Data/Tmp/rasa`中      |
| python_venv    | xxx                             | rasa所需python虚拟环境的位置，如果使用`install_rasa.sh`安装则位于`${project_home}/lib/rasa/bin/activate` |

# rasa配置

rasa配置目录在`Data/rasa`中,[文档](https://rasa.com/docs/rasa/)

rasa NLU的目的是从文本中抽取出意图和实体，例如`[增大](trend)音量`，它的意图是`CHANGE_VOL`,其中包含`trend`实体

rasa训练命令为`rasa train nlu -c config.yml`。训练完成之后在model文件夹下会生成一个模型，如果需要替换需要更改config.json中的配置并重新启动。



## 流水线

流水线是rasa NLU的处理流程，大致可以分为tokenizer, featurizer,intent classifier,entity classfier。流水线配置在`Data/rasa/config.yml`中，[文档位于](https://rasa.com/docs/rasa/components)

- tokenizer: 分词，中文一般使用jieba分词
- featurizer: 词向量化
- intent classifier: 意图抽取
- entity classfier: 实体抽取

## 实体和意图

可以参照`Data/rasa/domain.yml`进行配置，其训练语料位于`Data/rasa/data/nlu`中，如果想自定义实体和意图可以在domain.yml中添加定义，然后再data/nlu中添加训练语料，然后运行训练命令训练，最后在config.yml中修改模型位置即可

